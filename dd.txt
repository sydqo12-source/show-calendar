from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
import re

# ======================================================
# 1. ì§€ì—­/ë„ì‹œ ë§¤í•‘ ë¡œì§ (ìµœì‹  ë°˜ì˜: ë„ì‹œ ì´ë¦„ ìš°ì„ )
# ======================================================
def parse_region(text):
    if not text: return "(ê¸°íƒ€)"
    clean_text = text.replace(" ", "").lower()
    
    # [1ìˆœìœ„] ê´‘ì—­ì‹œ ë° íŠ¹ë³„ì‹œ
    if "ì„œìš¸" in clean_text or "seoul" in clean_text: return "(ì„œìš¸)"
    if "ë¶€ì‚°" in clean_text or "busan" in clean_text: return "(ë¶€ì‚°)"
    if "ëŒ€êµ¬" in clean_text or "daegu" in clean_text: return "(ëŒ€êµ¬)"
    if "ì¸ì²œ" in clean_text or "incheon" in clean_text: return "(ì¸ì²œ)"
    if "ëŒ€ì „" in clean_text or "daejeon" in clean_text: return "(ëŒ€ì „)"
    if "ìš¸ì‚°" in clean_text or "ulsan" in clean_text: return "(ìš¸ì‚°)"
    if "ì„¸ì¢…" in clean_text or "sejong" in clean_text: return "(ì„¸ì¢…)"
    if "ì œì£¼" in clean_text or "jeju" in clean_text: return "(ì œì£¼)"
    
    if "ê´‘ì£¼" in clean_text:
        if "ê²½ê¸°" in clean_text: return "(ê²½ê¸°)"
        return "(ê´‘ì£¼)"

    # [2ìˆœìœ„] ë„ì‹œ ì´ë¦„ ì—­ì¶”ì  (ì˜ˆìˆ ì˜ì „ë‹¹ë³´ë‹¤ ìš°ì„ !)
    
    # [ê²½ê¸°]
    gyeonggi_cities = [
        "ìˆ˜ì›", "ì„±ë‚¨", "ì˜ì •ë¶€", "ì•ˆì–‘", "ë¶€ì²œ", "ê´‘ëª…", "í‰íƒ", "ì•ˆì‚°", "ê³ ì–‘", "ì¼ì‚°", 
        "ê³¼ì²œ", "êµ¬ë¦¬", "ë‚¨ì–‘ì£¼", "ì˜¤ì‚°", "ì‹œí¥", "êµ°í¬", "ì˜ì™•", "í•˜ë‚¨", "ìš©ì¸", "íŒŒì£¼", 
        "ì´ì²œ", "ê¹€í¬", "í™”ì„±", "ê´‘ì£¼", "ì–‘ì£¼", "í¬ì²œ", "ì—¬ì£¼", "ì—°ì²œ", "ê°€í‰", "ì–‘í‰", 
        "í‚¨í…ìŠ¤", "kintex", "ì•„ëŒëˆ„ë¦¬", "ì–´ìš¸ë¦¼"
    ]
    if any(c in clean_text for c in gyeonggi_cities): return "(ê²½ê¸°)"

    # [ê°•ì›]
    if any(c in clean_text for c in ["ì¶˜ì²œ", "ì›ì£¼", "ê°•ë¦‰", "ì†ì´ˆ", "ë™í•´", "íƒœë°±", "ì‚¼ì²™"]): return "(ê°•ì›)"
    # [ì¶©ë¶]
    if any(c in clean_text for c in ["ì²­ì£¼", "ì¶©ì£¼", "ì œì²œ"]): return "(ì¶©ë¶)"
    # [ì¶©ë‚¨]
    if any(c in clean_text for c in ["ì²œì•ˆ", "ê³µì£¼", "ë³´ë ¹", "ì•„ì‚°", "ë‹¹ì§„", "ì„œì‚°", "ë…¼ì‚°"]): return "(ì¶©ë‚¨)"
    # [ì „ë¶]
    if any(c in clean_text for c in ["ì „ì£¼", "êµ°ì‚°", "ìµì‚°", "ì •ì", "ë‚¨ì›"]): return "(ì „ë¶)"
    # [ì „ë‚¨]
    if any(c in clean_text for c in ["ëª©í¬", "ì—¬ìˆ˜", "ìˆœì²œ", "ê´‘ì–‘", "ë‚˜ì£¼"]): return "(ì „ë‚¨)"
    # [ê²½ë¶]
    if any(c in clean_text for c in ["í¬í•­", "ê²½ì£¼", "ê¹€ì²œ", "ì•ˆë™", "êµ¬ë¯¸", "ì˜ì£¼", "ì˜ì²œ", "ìƒì£¼", "ë¬¸ê²½", "ê²½ì‚°"]): return "(ê²½ë¶)"
    # [ê²½ë‚¨]
    if any(c in clean_text for c in ["ì°½ì›", "ì§„ì£¼", "í†µì˜", "ì‚¬ì²œ", "ê¹€í•´", "ë°€ì–‘", "ê±°ì œ", "ì–‘ì‚°", "ë²¡ìŠ¤ì½”", "bexco"]): return "(ê²½ë‚¨)"

    # [3ìˆœìœ„] ì„œìš¸ ì£¼ìš” ê³µì—°ì¥ (ë„ì‹œ ì´ë¦„ ì—†ì„ ë•Œ)
    seoul_venues = [
        "ë§í¬ì•„íŠ¸ì„¼í„°", "ë“œë¦¼ì•„íŠ¸ì„¼í„°", "ëŒ€í•™ë¡œ", "í˜œí™”", "ì˜ˆìˆ ì˜ì „ë‹¹", "ì„¸ì¢…ë¬¸í™”", 
        "ë¡¯ë°ì½˜ì„œíŠ¸", "ë¸”ë£¨ìŠ¤í€˜ì–´", "ì ì‹¤", "ì˜¬ë¦¼í”½ê³µì›", "ì½”ì—‘ìŠ¤", "ë””íë¸Œ", "ìƒ¤ë¡¯ë°", 
        "lgì•„íŠ¸", "ì¶©ë¬´ì•„íŠ¸", "êµ­ë¦½ê·¹ì¥", "í•œì „ì•„íŠ¸", "ë§ˆí¬", "ìœ ë‹ˆí”Œë ‰ìŠ¤", "ì˜ˆìŠ¤24", 
        "kt&g", "í™ëŒ€", "ì„±ìˆ˜", "ê°•ë‚¨", "ëª…í™”ë¼ì´ë¸Œ", "tom", "í”ŒëŸ¬ìŠ¤ì”¨ì–´í„°", "ì•„íŠ¸ì›", "ììœ ê·¹ì¥"
    ]
    if any(v in clean_text for v in seoul_venues): return "(ì„œìš¸)"

    # [4ìˆœìœ„] ë„ ë‹¨ìœ„ ëª…ì¹­
    if "ê²½ê¸°" in clean_text: return "(ê²½ê¸°)"
    if "ê°•ì›" in clean_text: return "(ê°•ì›)"
    if "ì¶©ë¶" in clean_text or "ì¶©ì²­ë¶" in clean_text: return "(ì¶©ë¶)"
    if "ì¶©ë‚¨" in clean_text or "ì¶©ì²­ë‚¨" in clean_text: return "(ì¶©ë‚¨)"
    if "ì „ë¶" in clean_text or "ì „ë¼ë¶" in clean_text: return "(ì „ë¶)"
    if "ì „ë‚¨" in clean_text or "ì „ë¼ë‚¨" in clean_text: return "(ì „ë‚¨)"
    if "ê²½ë¶" in clean_text or "ê²½ìƒë¶" in clean_text: return "(ê²½ë¶)"
    if "ê²½ë‚¨" in clean_text or "ê²½ìƒë‚¨" in clean_text: return "(ê²½ë‚¨)"

    return "(ê¸°íƒ€)"

def get_address_from_map(driver, place_name):
    try:
        url = f"https://map.naver.com/p/search/{place_name}"
        driver.get(url)
        time.sleep(1.5)
        try:
            driver.switch_to.default_content()
            iframe = WebDriverWait(driver, 3).until(EC.presence_of_element_located((By.ID, "searchIframe")))
            driver.switch_to.frame(iframe)
            return driver.find_element(By.TAG_NAME, "body").text
        except:
            return ""
    except:
        return ""
    finally:
        driver.switch_to.default_content()

# ======================================================
# 2. í¬ë¡¤ë§ ì‹¤í–‰
# ======================================================
options = webdriver.ChromeOptions()
options.add_argument('--disable-blink-features=AutomationControlled')
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

url = "https://tickets.interpark.com/contents/notice"
driver.get(url)

print("====== â³ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ë¥˜ ì¤‘... ======")
time.sleep(5)

ticket_list = []

try:
    wait = WebDriverWait(driver, 20)
    filter_el = wait.until(EC.presence_of_element_located((By.XPATH, "//*[contains(text(), 'ì˜¤í”ˆìˆœ')]")))
    driver.execute_script("arguments[0].scrollIntoView();", filter_el)
    time.sleep(3)

    collected_titles = set()
    date_pattern = re.compile(r'(\d{2}\.\d{2}\(.\)\s\d{2}:\d{2})')

    for _ in range(20): 
        body_text = driver.find_element(By.TAG_NAME, "body").get_attribute("innerText")
        parts = re.split(date_pattern, body_text)
        
        for i in range(1, len(parts), 2):
            open_date = parts[i].strip()
            content = parts[i+1].strip()
            lines = [l.strip() for l in content.split('\n') if l.strip()]
            
            if len(lines) >= 2:
                title = lines[0]
                location = lines[1]
                
                if location.strip() in ["ë‹¤ìŒ", "ì´ì „", "ë§¨ì²˜ìŒ", "ë§¨ë", "TOP", "ëª©ë¡"]: continue
                if "ì¶”í›„ê³µì§€" in title or "ì¶”í›„ê³µì§€" in location: continue
                if "í‹°ì¼“" in title and "ì•ˆë‚´" in title: continue 
                
                if title not in collected_titles and len(title) > 2:
                    ticket_list.append({
                        'ì˜¤í”ˆì¼ì‹œ': open_date,
                        'ì§€ì—­': '', 
                        'ì œëª©': title,
                        'ì¥ì†Œ': location,
                        'ì¥ë¥´': 'ì„ íƒ'
                    })
                    collected_titles.add(title)

        driver.execute_script("window.scrollBy(0, 500);")
        time.sleep(1.5)
        if driver.execute_script("return window.pageYOffset + window.innerHeight >= document.body.scrollHeight"):
            break

    print(f"====== âœ… 1ë‹¨ê³„ ì™„ë£Œ! ì´ {len(ticket_list)}ê±´. ì§€ì—­ ê²€ì¦ ì‹œì‘... ======")

    place_cache = {} 
    for idx, item in enumerate(ticket_list):
        place = item['ì¥ì†Œ']
        title = item['ì œëª©']
        region = "(ê¸°íƒ€)"
        
        if place in place_cache:
            region = place_cache[place]
        else:
            full_text = place + " " + title
            temp_region = parse_region(full_text)
            
            if temp_region != "(ê¸°íƒ€)":
                region = temp_region
                if "ì˜ì •ë¶€" in place or "ì•ˆì‚°" in place:
                    print(f"âš¡ [í™•ì¸] {place} -> {region}")
            else:
                map_text = get_address_from_map(driver, place)
                if map_text:
                    region = parse_region(map_text)
                    print(f"[{idx+1}] ğŸ—ºï¸ ì§€ë„ê²€ìƒ‰: {place} -> {region}")
                else:
                    region = temp_region
            place_cache[place] = region
        
        item['ì§€ì—­'] = region

    # ======================================================
    # 3. ì—‘ì…€ ì €ì¥ (ì½¤ë³´ë°•ìŠ¤ ìˆ˜ì •ë¨)
    # ======================================================
    if ticket_list:
        df = pd.DataFrame(ticket_list)
        df = df.sort_values(by='ì˜¤í”ˆì¼ì‹œ', ascending=True)
        df = df[['ì˜¤í”ˆì¼ì‹œ', 'ì§€ì—­', 'ì œëª©', 'ì¥ì†Œ', 'ì¥ë¥´']]
        
        output_file = 'ê³µì—°ëª©ë¡_ì˜¤í”ˆì˜ˆì •.xlsx'
        
        writer = pd.ExcelWriter(output_file, engine='xlsxwriter')
        df.to_excel(writer, index=False, sheet_name='Sheet1')

        workbook = writer.book
        worksheet = writer.sheets['Sheet1']

        # [ìˆ˜ì •ë¨] 'ë‚´í•œ' ì œê±°
        genre_options = ['ì½˜ì„œíŠ¸', 'ë®¤ì§€ì»¬', 'ì—°ê·¹', 'í´ë˜ì‹', 'í–‰ì‚¬(ì „ì‹œ)', 'ê°€ì¡±']
        last_row = len(df) + 1
        
        worksheet.data_validation(f'E2:E{last_row}', {
            'validate': 'list',
            'source': genre_options,
            'input_title': 'ì¥ë¥´ ì„ íƒ',
            'input_message': 'ëª©ë¡ì—ì„œ ì¥ë¥´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.'
        })

        worksheet.set_column('A:A', 15)
        worksheet.set_column('B:B', 8)
        worksheet.set_column('C:C', 45)
        worksheet.set_column('D:D', 30)
        worksheet.set_column('E:E', 12)

        writer.close()
        print(f"\nğŸ‰ ì €ì¥ ì™„ë£Œ! '{output_file}'ì˜ ì¥ë¥´ ëª©ë¡ì—ì„œ 'ë‚´í•œ'ì´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nğŸ˜¢ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
finally:
    driver.quit()